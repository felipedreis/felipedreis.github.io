---
layout: post
title: "Unpacking ChatGPT: is AGI that close?"
date:   2024-09-24 12:00:00 +0100
categories: blog 
short_intro: ""
highlights:
    - What powers these 

---

After the popularization of ChatGPT, a lot of promises were made and noise was  
formed around the possibility of LLMs (Large Language Models)  
being the next step to the so-called AGI (Artificial General Intelligence). 
Many people are concerned and fear losing their jobs to the AGI. 
These thoughts come from the lack of perception of how the 
Large Language Model that powers ChatGPT works. 

Underlying the fancy name, everything behind LLM is a lot of neural 
networks carefully combined. The ANN (Artificial Neural Network) is an AI technique
that relies on algebra (more specifically, matrix multiplications) and calculus
(backpropagation uses partial derivatives). 
Modern NVIDIA processors power these operations and have very high computational costs.

LLMs are, in fact, a complex architecture of many layers and "submodels", 
trained in a very well-curated  dataset.
This curation starts early in how to obtain embeddings that "make sense"
and can be interpreted in a vectorial space. The data for the training 
phase of GPT is carefully designed to tackle each subtask, from text classification
to multiple-choice answers. 

The technical part put asside, when we talk about general intelligence, we have
to be careful. Intelligence is a complex behaviour observed in living creatures,
specially the ones endowed with a central nervous system. 


<!--

## What's a large language model? 

In short words, a LLM is an artificial intelligence technique based on a neural
network  that is trained to predict the next word based on a sequence of word.
This explanation is something between the sacle of simplification-overcomplexity

```
        we are here 
           |
    |------x-------------------------------------------------------|
 its just                                                       linear
 predicting                                                     algebra
 the next word 
```

This is clearly not enough to understand better what this models are doing.
But how we can do it an how should we proceed? The main reason to undertand it 
better is because this kind of technology will become more imbricated in our
day-to-day life. A lot of hype already exists yet and all this noise is 
distractful.

For the how question, I believe there are many ways to get a minimal understanding
of a LLM architecture. Even for me, I started with many different YouTube videos, 
in special, the recent series from 3blue1brown. There's also a very good talk
from Jeff Dean that walks us through the main contributions of the natural
proccessing language that lead to what we know today for LLM. It was also enlightening 
for me reading the papers Dean mentions in his talk, they explain composing parts
of a LLM. And this is what we gonna explore in this article.

Taking the most famous model, the GPT, and breaking the achrnym apart, it means
Generative Pre-Trained Transformers. We gonna explore the pre-training concept, 
the generative part, and the most fundamental one, the transformer. But before that
we need to go through something more fundamental that is a Artificial Neural Network.

## Artificial Neural Networks 

ANN are the building blocks of most of modern AI applications. The name of the 
tecnhnique comes from the inspiration of biological neurons. Besides the name,
the inspiration stops here, since a real neuron is far more complex than a their 
artificial counterparts used to recognize images, predict your next favorite movie
or generate a paragraph of text.

An artificial neuron is often represented as the following image, where you 
have a series of input that has weights associated, after being weighted
they are combined in some way and goes trough an activation function. 
This activation function says if this neuron is active or not. 

Mathematically, the input can be represented as a vector, as the neuron weights.
The step to combine both input and weights is actually pretty simple. As they
have the same size, we can multiply each corresponding value and add them up.
In algebra this is called internal product. This product will produce a single 
number, what is perfect to feed our activation function. We can use many different
functions, the most famous are the sigmoid and retified linear unit (ReLU). This 
is how a single neuron works, but we can also combine multiple neurons into 
multiple layers with multiple outputs. This composability of ANN makes it 
a kind of universal function modeller. 

If, for example, we have a network with weights w = [1, -1, 1], and an input 
x = [0, 1, 0], the internal product of both vectors is x*w = 1x0 + 

In ANN there's to phases, the training phase, and inference phase. Training phase
is the core part of ANN, where we gonna discover the weights of our network 
based on the problem we want to solve. This involves initializing the weights with
random non-zero values, evaluate the result of the network 

## Making words into vectors

As we saw above, neural networks understand vectrors. But we humans use words 
as the basic construct to communicate. How can we translate words into something
that can be fed to NN? There are many ways we can do that, for example we can
transform our dataset in a binary dictionary and feed it to a network. Suppose
our dataset is composed of words "This is my dataset". The dictionary will looks
like something like this:

```
'00' => "this"
'01' => "is"
'10' => "my"
'11' => "dataset"
```
We can then interpret each key as a binary vector of dimension 2, e.g. the vector
for "this" would be `v = [0, 0]` and the one for dataset would be `v = [1, 1]`. 
We know can feed this vectors to a network. This representation is simple, 
you can do it compactly with some optimizations, but these vectors lacks a lot 
of desirable properties. They have spatial relationship. Words that have similar 
meanings might fall distant from each other. 

One clever solution to these un
-->
